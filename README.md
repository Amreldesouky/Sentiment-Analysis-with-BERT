# Sentiment Analysis with BERT

## 📌 Project Overview

This project implements **Sentiment Analysis** using **BERT (Bidirectional Encoder Representations from Transformers)**, a state-of-the-art deep learning model for **natural language processing (NLP)**. Our model classifies text reviews into sentiment categories, providing insights into user opinions with high accuracy.

## 🚀 Features

- **Pre-trained BERT Model**: Utilizes `bert-base-uncased` for powerful contextual understanding.
- **Handles Various Sentiments**: giving score from 1 to 5 according to Satisfaction level. 
- **Efficient Tokenization**: Uses the Hugging Face `transformers` library for text preprocessing.
- **CUDA Support**: Runs efficiently on GPUs for faster inference.

## 📂 Project Structure

## 🔧 Installation

1. Clone the repository:
2. Create a virtual environment and install dependencies:

## 🛠️ Usage

### 2️⃣ Running Inference


## ⚡ Performance Insights

- The model performed very well and much better than the clients scores records .
- Leveraging **BERT’s contextual embeddings** significantly improved classification for complex reviews.
- GPU acceleration led to **faster inference times**, reducing prediction latency.

## 🏗️ Future Improvements

- **Expand Dataset**: Train on a larger and more diverse dataset for improved generalization.

## 💡 Technologies Used

- **Python** 🐍
- **PyTorch** 🔥
- **Transformers (Hugging Face)** 🤗
- **BERT** 🧠
- **CUDA (GPU Acceleration)** ⚡

## 🤝 Contributing

Contributions are welcome! Feel free to fork the repo and submit pull requests.


---

**Developed by [Amr Khaled Eldesouky]** ✨



